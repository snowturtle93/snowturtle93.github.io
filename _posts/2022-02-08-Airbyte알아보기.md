---
title: "Airbyte알아보기"
author: Kang HyunGu
date: 2022-02-08 19:26:00 +0900
categories: [Bigdata, BI&DW]
tags: [Bigdata]
toc: true
pin: true
comments: true
---

오늘은 opensource ELT솔루션인 Airbyte에 대해 알아보려고 한다.
중점적으로 알아볼것들은 설치 방법, 사용 방법, 장단점이다.
설치와 사용을 해보고 다시 보니 Airbyte는 ETL솔루션이 아닌 ELT솔루션으로 소개되어있는걸 보아 글 마지막에 정리되어있는 단점이 이해가 가게되었다.


## 1. 설치 방법
- 설치는 간단하게 도커위에 컨테이너로 설치가 되기 때문에 아래 명령어로 설치를 진행한다.
```
git clone https://github.com/airbytehq/airbyte.git
cd airbyte
docker-compose up
```
- 설치 완료시 메인 화면
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/web_main.png" width="900" height="450"></p>

## 2. 사용 방법
### 2.1 Source 만들기

여기서 말하는 Source는 ETL에서 Extract(추출)할 데이터의 저장소 또는 주소를말한다.
- 우측 상단의 new connection 클릭.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_source_01.png" width="900" height="350"></p>
- Source TYPE 선택 후 접속정보 채워넣기.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_source_01.png" width="400" height="550"></p>
접속 정보를 채워 넣고 복제 방법에 대한 선택을 하는데 여기서 신기하게도 CDC(Change Data Capture)로 2실시간 복제 할수가 있다는 점에서 기존의 ETL 툴과는 다른 점이 보였다.
이것만으로도 Airbyte를 사용할 이유가 있어보였다 실제로 어떻게 작동할지는 추 후 알아보기로 하고 이번에는 기본 모드로 복제를 하도록한다.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_source_01.png" width="900" height="250"></p>

### 2.2 Target 만들기

여기서 말하는 Target은 ETL에서 Load(적재)할 데이터의 저장소 또는 주소를 말한다.
- Target TYPE 선택 후 정보 채워넣기.
아쉽게도 HDFS가 없어 csv파일 형식으로 로컬에 내려 놓는 방식을 테스트해본다.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_target_01.png" width="700" height="450"></p>
- Sync frequency 설정.
보통 내가 사용해본 ETL 솔루션(Pentaho PDI,Informatica PowerCenter)과는 사용법이 좀 다른거 같은데 데이터를 이관하는 방법이 SQL이나 GUI로 만들어 내는것이 아니고 1:1 맵핑으로 데이터를 적재하는것 같은데 내가 생각한 것과는 조금 달라 사용하기는 어려워 보인다.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_target_02.png" width="700" height="450"></p>
- Sync mode 설정
Sync mode에는 full refresh:overwrite, refresh:append, Incremental:Append 가있는데 Incremental:Append 에는 증분해서 가져올 primary key가 지정이 되어 있어야 하는것 같다.
이번에는 테스트이기 때문에 overwrite하도록한다.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_target_03.png" width="700" height="450"></p>

### 2.3 배치 실행.
커넥션을 만들고 난뒤 Launch버튼을 눌러 배치를 실행시킨다.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_target_04.png" width="700" height="150"></p>
데이터를 csv로 저장했는데 json 형태로 저장되는걸 보고 파일로 내려 받아서 사용하기에는 힘들겠구나라는 생강을 받았다.
test1,2,3,4 라는 데이터를 csv로 저장한 모습.
<p align="left"> <img src="{{site.url}}/img/posts/airbyte/create_target_05.png" width="700" height="150"></p>

## 3.장/단점
장점과 단점을 정리하다 보니 Spark를 사용하여 Spring Boot + Spark로 웹 어플리케이션을 만들어 ETL 데이터 처리 시스템을 만들어 보는게 좋겠다는 생각이 들었다.

### 3.1 장점
- cdc기능으로 준실시간간으로 데이터를 가져올수 있다는 장점.
- 1:1 맵핑으로는 간단하게 데이터를 저장할 수 있고 설치도 간편하다.
-  지원하는 데이터 Source가 굉장히 많다.
    - 데이터 베이스외에도 SNS나 앱 데이터도 연동이 가능한거 같다.

### 3.2 단점
- ETL 툴에서 T(Transform)가 없는 툴같아서 반쪽짜리 툴이라고 느껴졌다.
    - Source SQL 사용이 어려워 보임.
    - GUI 환경으로 할 수 있는 Transform 기능이 없다.
- csv 형태가 데이터 원본 그대로 적재되는 형태가 아니다.
- HDFS 저장이 안된다.
